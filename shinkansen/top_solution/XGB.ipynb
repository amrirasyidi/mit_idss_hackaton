{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1\n"
     ]
    }
   ],
   "source": [
    "# check xgboost version\n",
    "import xgboost as xgb\n",
    "print(xgb.__version__)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# For tuning the model\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('/Users/zoso/Documents/Courses and Certifications/MIT_machineLearning/Shinkansen Travel Experience/X_train.csv')\n",
    "X_test = pd.read_csv('/Users/zoso/Documents/Courses and Certifications/MIT_machineLearning/Shinkansen Travel Experience/X_test.csv')\n",
    "y_train = pd.read_csv('/Users/zoso/Documents/Courses and Certifications/MIT_machineLearning/Shinkansen Travel Experience/y_train.csv')\n",
    "\n",
    "X_nulls_train = pd.read_csv('/Users/zoso/Documents/Courses and Certifications/MIT_machineLearning/Shinkansen Travel Experience/X_nulls_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''xgb.set_config(verbosity=0)\n",
    "\n",
    "# Get current value of global configuration\n",
    "\n",
    "# This is a dict containing all parameters in the global configuration,\n",
    "\n",
    "# including 'verbosity'\n",
    "\n",
    "config = xgb.get_config()\n",
    "assert config['verbosity'] == 2'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "meta = .19\n",
    "max depth = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best: 0.953146 using {'subsample': 0.8999999999999999, 'reg_lambda': 0.1, 'reg_alpha': 0.8, 'min_child_weight': 3.499999999999999, 'max_depth': 9, 'gamma': 0.31000000000000005, 'eta': 0.17999999999999997, 'colsample_bytree': 0.8999999999999999}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best: 0.954492 using {'tree_method': 'approx', 'subsample': 0.8999999999999999, 'reg_lambda': 0.0, 'reg_alpha': 0.31, 'min_child_weight': 2.9999999999999996, 'max_depth': 12, 'gamma': 0.67, 'eta': 0.18999999999999995, 'colsample_bytree': 0.7999999999999999, 'colsample_bylevel': 0.8999999999999999}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best: 0.954789 using {'tree_method': 'hist', 'subsample': 0.8999999999999999, 'reg_lambda': 0.42, 'reg_alpha': 0.54, 'min_child_weight': 1.7999999999999998, 'max_depth': 9, 'gamma': 0.24000000000000002, 'eta': 0.15999999999999998, 'colsample_bytree': 0.7999999999999999, 'colsample_bylevel': 0.5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best: 0.955626 using {'tree_method': 'auto', 'subsample': 0.8999999999999999, 'sampling_method': 'uniform', 'reg_lambda': 0.62, 'reg_alpha': 0.77, 'min_child_weight': 0.7999999999999999, 'max_depth': 9, 'gamma': 0.91, 'eta': 0.19999999999999996, 'colsample_bytree': 0.8999999999999999, 'colsample_bylevel': 0.6}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best: 0.956018 using {'tree_method': 'auto', 'subsample': 0.8999999999999999, 'sampling_method': 'uniform', 'reg_lambda': 0.81, 'reg_alpha': 0.88, 'num_parallel_tree': 8, 'min_child_weight': 2.7999999999999994, 'max_depth': 9, 'gamma': 0.66, 'eta': 0.19999999999999996, 'colsample_bytree': 0.7, 'colsample_bylevel': 0.7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ID = X_train.copy()\n",
    "X_ID_test = X_test.copy()\n",
    "X_train = X_train.drop(columns=['ID'])\n",
    "X_test = X_test.drop(columns=['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions using xgboost for classification\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier()\n",
    "\n",
    "model = XGBClassifier(tree_method = 'auto',subsample= 0.8999999999999999, sampling_method = 'uniform',reg_lambda=.81,reg_alpha=0.88,num_parallel_tree= 8,min_child_weight= 2.7999999999999994, max_depth= 9, gamma= 0.66, eta= 0.19999999999999996, colsample_bytree= 0.7,colsample_bylevel=0.7)\n",
    "# fit the model on the whole dataset\n",
    "model.fit(X_train, y_train)\n",
    "# make a single prediction\n",
    "yhat = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Overall_Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99900001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99900002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99900003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99900004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99900005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35597</th>\n",
       "      <td>99935598</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35598</th>\n",
       "      <td>99935599</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35599</th>\n",
       "      <td>99935600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35600</th>\n",
       "      <td>99935601</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35601</th>\n",
       "      <td>99935602</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35602 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID  Overall_Experience\n",
       "0      99900001                   1\n",
       "1      99900002                   1\n",
       "2      99900003                   1\n",
       "3      99900004                   0\n",
       "4      99900005                   1\n",
       "...         ...                 ...\n",
       "35597  99935598                   0\n",
       "35598  99935599                   1\n",
       "35599  99935600                   0\n",
       "35600  99935601                   1\n",
       "35601  99935602                   0\n",
       "\n",
       "[35602 rows x 2 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.array(yhat)\n",
    "id = np.array(X_ID_test['ID'])\n",
    "pred_y = pd.DataFrame([id,pred])\n",
    "sumbmission =pred_y.T.rename(columns={0:'ID',1:'Overall_Experience'})\n",
    "sumbmission.to_csv('/Users/zoso/Documents/Courses and Certifications/MIT_machineLearning/Shinkansen Travel Experience/Sumbmission_XGB.csv',index=False)\n",
    "sumbmission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <bound method DataIter._next_wrapper of <xgboost.data.SingleBatchInternalIter object at 0x7fcc309c4a30>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/base2/lib/python3.9/site-packages/xgboost/core.py\", line 500, in _next_wrapper\n",
      "    def _next_wrapper(self, this: None) -> int:  # pylint: disable=unused-argument\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/zoso/Documents/Courses and Certifications/MIT_machineLearning/Shinkansen Travel Experience/Code.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zoso/Documents/Courses%20and%20Certifications/MIT_machineLearning/Shinkansen%20Travel%20Experience/Code.ipynb#X35sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m kfold_splits \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zoso/Documents/Courses%20and%20Certifications/MIT_machineLearning/Shinkansen%20Travel%20Experience/Code.ipynb#X35sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m random\u001b[39m=\u001b[39m RandomizedSearchCV(estimator\u001b[39m=\u001b[39mxgb,  \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zoso/Documents/Courses%20and%20Certifications/MIT_machineLearning/Shinkansen%20Travel%20Experience/Code.ipynb#X35sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m                     verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zoso/Documents/Courses%20and%20Certifications/MIT_machineLearning/Shinkansen%20Travel%20Experience/Code.ipynb#X35sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m                     cv\u001b[39m=\u001b[39mkfold_splits,  \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zoso/Documents/Courses%20and%20Certifications/MIT_machineLearning/Shinkansen%20Travel%20Experience/Code.ipynb#X35sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m                     param_distributions\u001b[39m=\u001b[39mparam_random,n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/zoso/Documents/Courses%20and%20Certifications/MIT_machineLearning/Shinkansen%20Travel%20Experience/Code.ipynb#X35sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m random_result \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39;49mfit(X_train, y_train,verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m) \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zoso/Documents/Courses%20and%20Certifications/MIT_machineLearning/Shinkansen%20Travel%20Experience/Code.ipynb#X35sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# Summarize results\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zoso/Documents/Courses%20and%20Certifications/MIT_machineLearning/Shinkansen%20Travel%20Experience/Code.ipynb#X35sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest: \u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m using \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (random_result\u001b[39m.\u001b[39mbest_score_, random_result\u001b[39m.\u001b[39mbest_params_))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/base2/lib/python3.9/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/base2/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1753\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1751\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1752\u001b[0m     \u001b[39m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1753\u001b[0m     evaluate_candidates(\n\u001b[1;32m   1754\u001b[0m         ParameterSampler(\n\u001b[1;32m   1755\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_distributions, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_iter, random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state\n\u001b[1;32m   1756\u001b[0m         )\n\u001b[1;32m   1757\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/base2/lib/python3.9/site-packages/sklearn/model_selection/_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    819\u001b[0m         )\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 822\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    823\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    824\u001b[0m         clone(base_estimator),\n\u001b[1;32m    825\u001b[0m         X,\n\u001b[1;32m    826\u001b[0m         y,\n\u001b[1;32m    827\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    828\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    829\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    830\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    831\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    832\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    833\u001b[0m     )\n\u001b[1;32m    834\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    835\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    836\u001b[0m     )\n\u001b[1;32m    837\u001b[0m )\n\u001b[1;32m    839\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/base2/lib/python3.9/site-packages/joblib/parallel.py:1061\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1061\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1062\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m/opt/anaconda3/envs/base2/lib/python3.9/site-packages/joblib/parallel.py:938\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    936\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 938\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    939\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    940\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m/opt/anaconda3/envs/base2/lib/python3.9/site-packages/joblib/_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 542\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    543\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/base2/lib/python3.9/concurrent/futures/_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 441\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    444\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/base2/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# define the grid search parameters\n",
    "xgb = XGBClassifier()#(tree_method = 'approx',subsample= 0.8999999999999999, reg_lambda=0.001,reg_alpha=0.31,min_child_weight= 2.9999999999999996, gamma= 0.67, eta= 0.18999999999999995, colsample_bytree= 0.7999999999999999,colsample_bylevel=0.8999999999999999)\n",
    "param_random = {\n",
    "    'gamma':np.arange(.01,1,.01),\n",
    "    'eta':np.arange(.1,.3,.01),\n",
    "    'max_depth' : np.arange(2,10),\n",
    "    'colsample_bytree':np.arange(.5,1,.1),\n",
    "    'subsample':np.arange(.5,1,.1),\n",
    "    'min_child_weight':np.arange(.5,5,.1),\n",
    "    'reg_lambda':np.arange(0,1,.01),\n",
    "    'reg_alpha':np.arange(0,1,.01),\n",
    "    'colsample_bylevel':np.arange(.5,1,.1),\n",
    "    'tree_method':['auto','exact','approx','hist','gpu_hist'],\n",
    "    #'booster':['gbtree','dart'],\n",
    "    #'max_delta_step' : np.arange(11)\n",
    "    'sampling_method':['uniform','gradient_based'],\n",
    "    #'scale_pos_weight' : np.arange(.5,1,.01),\n",
    "    #'refresh_leaf':[0,1],\n",
    "    'num_parallel_tree':np.arange(1,20),\n",
    "    #'updater': ['grow_colmaker','grow_histmaker','grow_quantile_histmaker','grow_gpu_hist','sync','refresh','prune'],\n",
    "    #'process_type':['deafult','update']\n",
    "    }\n",
    "\n",
    "kfold_splits = 10\n",
    "random= RandomizedSearchCV(estimator=xgb,  \n",
    "                    verbose=1,\n",
    "                    cv=kfold_splits,  \n",
    "                    param_distributions=param_random,n_jobs=-1)\n",
    "                    \n",
    "random_result = random.fit(X_train, y_train,verbose=1) \n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (random_result.best_score_, random_result.best_params_))\n",
    "means = random_result.cv_results_['mean_test_score']\n",
    "stds = random_result.cv_results_['std_test_score']\n",
    "params = random_result.cv_results_['params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best: 0.955965 using {'tree_method': 'hist', 'subsample': 0.8999999999999999, 'sampling_method': 'uniform', 'reg_lambda': 0.47000000000000003, 'reg_alpha': 0.01, 'num_parallel_tree': 4, 'min_child_weight': 3.999999999999999, 'max_depth': 8, 'gamma': 0.45, 'eta': 0.22999999999999995, 'colsample_bytree': 0.8999999999999999, 'colsample_bylevel': 0.7}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best: 0.956018 using {'tree_method': 'auto', 'subsample': 0.8999999999999999, 'sampling_method': 'uniform', 'reg_lambda': 0.81, 'reg_alpha': 0.88, 'num_parallel_tree': 8, 'min_child_weight': 2.7999999999999994, 'max_depth': 9, 'gamma': 0.66, 'eta': 0.19999999999999996, 'colsample_bytree': 0.7, 'colsample_bylevel': 0.7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions using xgboost for classification\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(tree_method = 'auto',subsample= 0.8999999999999999, sampling_method = 'uniform',reg_lambda=.81,reg_alpha=0.88,num_parallel_tree= 8,min_child_weight= 2.7999999999999994, max_depth= 9, gamma= 0.66, eta= 0.19999999999999996, colsample_bytree= 0.7,colsample_bylevel=0.7)\n",
    "# fit the model on the whole dataset\n",
    "model.fit(X_train, y_train)\n",
    "# make a single prediction\n",
    "yhat = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Overall_Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99900001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99900002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99900003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99900004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99900005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35597</th>\n",
       "      <td>99935598</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35598</th>\n",
       "      <td>99935599</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35599</th>\n",
       "      <td>99935600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35600</th>\n",
       "      <td>99935601</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35601</th>\n",
       "      <td>99935602</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35602 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID  Overall_Experience\n",
       "0      99900001                   1\n",
       "1      99900002                   1\n",
       "2      99900003                   1\n",
       "3      99900004                   0\n",
       "4      99900005                   1\n",
       "...         ...                 ...\n",
       "35597  99935598                   0\n",
       "35598  99935599                   1\n",
       "35599  99935600                   0\n",
       "35600  99935601                   1\n",
       "35601  99935602                   0\n",
       "\n",
       "[35602 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.array(yhat)\n",
    "id = np.array(X_test['ID'])\n",
    "pred_y = pd.DataFrame([id,pred])\n",
    "sumbmission =pred_y.T.rename(columns={0:'ID',1:'Overall_Experience'})\n",
    "sumbmission.to_csv('/Users/zoso/Documents/Courses and Certifications/MIT_machineLearning/Shinkansen Travel Experience/Sumbmission_XGB_tuned.csv',index=False)\n",
    "sumbmission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c08288ec6e62ecf03f81cdc3f495252c5f92143112a00aff2967ef1a9a75377f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
